{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Секція 1. Логістична регресія з нуля.**\n",
        "\n",
        "Будемо крок за кроком будувати модель лог регресії з нуля для передбачення, чи буде врожай більше за 80 яблук (задача подібна до лекційної, але на класифікацію).\n",
        "\n",
        "Давайте нагадаємо основні формули для логістичної регресії.\n",
        "\n",
        "### Функція гіпотези - обчислення передбачення у логістичній регресії:\n",
        "\n",
        "$$\n",
        "\\hat{y} = \\sigma(x W^T + b) = \\frac{1}{1 + e^{-(x W^T + b)}}\n",
        "$$\n",
        "\n",
        "Де:\n",
        "- $ \\hat{y} $ — це ймовірність \"позитивного\" класу.\n",
        "- $ x $ — це вектор (або матриця для набору прикладів) вхідних даних.\n",
        "- $ W $ — це вектор (або матриця) вагових коефіцієнтів моделі.\n",
        "- $ b $ — це зміщення (bias).\n",
        "- $ \\sigma(z) $ — це сигмоїдна функція активації.\n",
        "\n",
        "### Як обчислюється сигмоїдна функція:\n",
        "\n",
        "Сигмоїдна функція $ \\sigma(z) $ має вигляд:\n",
        "\n",
        "$$\n",
        "\\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
        "$$\n",
        "\n",
        "Ця функція перетворює будь-яке дійсне значення $ z $ в інтервал від 0 до 1, що дозволяє інтерпретувати вихід як ймовірність для логістичної регресії.\n",
        "\n",
        "### Формула функції втрат для логістичної регресії (бінарна крос-ентропія):\n",
        "\n",
        "Функція втрат крос-ентропії оцінює, наскільки добре модель передбачає класи, порівнюючи передбачені ймовірності $ \\hat{y} $ із справжніми мітками $ y $. Формула наступна:\n",
        "\n",
        "$$\n",
        "L(y, \\hat{y}) = - \\left[ y \\cdot \\log(\\hat{y}) + (1 - y) \\cdot \\log(1 - \\hat{y}) \\right]\n",
        "$$\n",
        "\n",
        "Де:\n",
        "- $ y $ — це справжнє значення (мітка класу, 0 або 1).\n",
        "- $ \\hat{y} $ — це передбачене значення (ймовірність).\n",
        "\n"
      ],
      "metadata": {
        "id": "lbLHTNfSclli"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.\n",
        "Тут вже наведений код для ініціювання набору даних в форматі numpy. Перетворіть `inputs`, `targets` на `torch` тензори. Виведіть результат на екран."
      ],
      "metadata": {
        "id": "GtOYB-RHfc_r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "3BNXSR-VdYKQ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "QLKZ77x4v_-v"
      },
      "outputs": [],
      "source": [
        "# Вхідні дані (temp, rainfall, humidity)\n",
        "inputs = np.array([[73, 67, 43],\n",
        "                   [91, 88, 64],\n",
        "                   [87, 134, 58],\n",
        "                   [102, 43, 37],\n",
        "                   [69, 96, 70]], dtype='float32')\n",
        "\n",
        "# Таргети (apples > 80)\n",
        "targets = np.array([[0],\n",
        "                    [1],\n",
        "                    [1],\n",
        "                    [0],\n",
        "                    [1]], dtype='float32')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = torch.from_numpy(inputs)\n",
        "targets = torch.from_numpy(targets)"
      ],
      "metadata": {
        "id": "KjoeaDrk6fO7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMTZZkhJqbAu",
        "outputId": "3d8bd843-bcb5-40d4-efff-edfdda01833c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 73.,  67.,  43.],\n",
              "        [ 91.,  88.,  64.],\n",
              "        [ 87., 134.,  58.],\n",
              "        [102.,  43.,  37.],\n",
              "        [ 69.,  96.,  70.]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "targets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r7zpPCZ4qebo",
        "outputId": "bc9fcbaa-aa38-44c2-ca1f-7ac6f9d6aa58"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.],\n",
              "        [1.],\n",
              "        [1.],\n",
              "        [0.],\n",
              "        [1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Ініціюйте ваги `w`, `b` для моделі логістичної регресії потрібної форми зважаючи на розмірності даних випадковими значеннями з нормального розподілу. Лишаю тут код для фіксації `random_seed`."
      ],
      "metadata": {
        "id": "iKzbJKfOgGV8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.random.manual_seed(1)"
      ],
      "metadata": {
        "id": "aXhKw6Tdj1-d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09f62c99-5949-454e-fbd4-93b24f2d164b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f64e0628c50>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w = torch.randn(1, 3, requires_grad=True)\n",
        "b = torch.randn(1, requires_grad=True)"
      ],
      "metadata": {
        "id": "eApcB7eb6h9o"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"w:\\n\", w)\n",
        "print(\"shape:\", tuple(w.shape))\n",
        "print(\"\\nb:\\n\", b)\n",
        "print(\"shape:\", tuple(b.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hiwBUPTlUPd",
        "outputId": "c8433a36-cf4a-41ed-93a3-8a3cb86ccdd4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "w:\n",
            " tensor([[0.6614, 0.2669, 0.0617]], requires_grad=True)\n",
            "shape: (1, 3)\n",
            "\n",
            "b:\n",
            " tensor([0.6213], requires_grad=True)\n",
            "shape: (1,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Напишіть функцію `model`, яка буде обчислювати функцію гіпотези в логістичній регресії і дозволяти робити передбачення на основі введеного рядка даних і коефіцієнтів в змінних `w`, `b`.\n",
        "\n",
        "  **Важливий момент**, що функція `model` робить обчислення на `torch.tensors`, тож для математичних обчислень використовуємо фукнціонал `torch`, наприклад:\n",
        "  - обчсилення $e^x$: `torch.exp(x)`\n",
        "  - обчсилення $log(x)$: `torch.log(x)`\n",
        "  - обчислення середнього значення вектору `x`: `torch.mean(x)`\n",
        "\n",
        "  Використайте функцію `model` для обчислення передбачень з поточними значеннями `w`, `b`.Виведіть результат обчислень на екран.\n",
        "\n",
        "  Проаналізуйте передбачення. Чи не викликають вони у вас підозр? І якщо викликають, то чим це може бути зумовлено?"
      ],
      "metadata": {
        "id": "nYGxNGTaf5s6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model(x):\n",
        "  return torch.sigmoid(x @ w.t() + b)"
      ],
      "metadata": {
        "id": "pSz2j4Fh6jBv"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = model(inputs)\n",
        "print(preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxlJVBZXrPTN",
        "outputId": "6e4f203c-9cba-439b-e9d8-9c23329558ae"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<SigmoidBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Спостереження:**\n",
        "\n",
        "Так як ваги були ініціалізовані рандомно моделі складно прогнозувати. Та вона могла застрягти в локальному мінімумі. Всі відповіді моделі дорівнюють 1."
      ],
      "metadata": {
        "id": "suKNU2XUrQQl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Напишіть функцію `binary_cross_entropy`, яка приймає на вхід передбачення моделі `predicted_probs` та справжні мітки в даних `true_labels` і обчислює значення втрат (loss)  за формулою бінарної крос-ентропії для кожного екземпляра та вертає середні втрати по всьому набору даних.\n",
        "  Використайте функцію `binary_cross_entropy` для обчислення втрат для поточних передбачень моделі."
      ],
      "metadata": {
        "id": "O2AGM0Mb2yHa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def binary_cross_entropy(predicted_probs, true_labels):\n",
        "  \"\"\"\n",
        "  Обчислює бінарну крос-ентропію.\n",
        "\n",
        "  Args:\n",
        "    predicted_probs: Передбачення моделі (torch.tensor).\n",
        "    true_labels: Справжні мітки (torch.tensor).\n",
        "\n",
        "  Returns:\n",
        "    Середні втрати (torch.tensor).\n",
        "  \"\"\"\n",
        "  loss = - (true_labels * torch.log(predicted_probs + 1e-10) +\n",
        "          (1 - true_labels) * torch.log(1 - predicted_probs + 1e-10))\n",
        "  return torch.mean(loss)"
      ],
      "metadata": {
        "id": "1bWlovvx6kZS"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = binary_cross_entropy(preds, targets)\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAe0ZLrHrhva",
        "outputId": "58ea98b2-6744-4b7a-dabe-2dd5f4abaa56"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(9.2103, grad_fn=<MeanBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Зробіть зворотнє поширення помилки і виведіть градієнти за параметрами `w`, `b`. Проаналізуйте їх значення. Як гадаєте, чому вони саме такі?"
      ],
      "metadata": {
        "id": "ZFKpQxdHi1__"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss.backward()\n",
        "print(w.grad)\n",
        "print(b.grad)"
      ],
      "metadata": {
        "id": "YAbXUNSJ6mCl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de31ccca-61ca-45c3-e130-a17b5a2f31e7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0.]])\n",
            "tensor([0.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Спостереження:**\n",
        "\n",
        "Градієнти 0 можуть значити, що модель погано навчилась. Бо вони вказують на напрямок, в якому потрібно змінити ваги зміщення, щоб зменшити втрати моделі"
      ],
      "metadata": {
        "id": "xSI9VFPDrySb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Що сталось?**\n",
        "\n",
        "В цій задачі, коли ми ініціювали значення випадковими значеннями з нормального розподілу, насправді ці значення не були дуже гарними стартовими значеннями і привели до того, що градієнти стали дуже малими або навіть рівними нулю (це призводить до того, що градієнти \"зникають\"), і відповідно при оновленні ваг у нас не буде нічого змінюватись. Це називається `gradient vanishing`. Це відбувається через **насичення сигмоїдної функції активації.**\n",
        "\n",
        "У нашій задачі ми використовуємо сигмоїдну функцію активації, яка має такий вигляд:\n",
        "\n",
        "   $$\n",
        "   \\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
        "   $$\n",
        "\n",
        "\n",
        "Коли значення $z$ дуже велике або дуже мале, сигмоїдна функція починає \"насичуватись\". Це означає, що для великих позитивних $z$ сигмоїда наближається до 1, а для великих негативних — до 0. В цих діапазонах градієнти починають стрімко зменшуватись і наближаються до нуля (бо градієнт - це похідна, похідна на проміжку функції, де вона паралельна осі ОХ, дорівнює 0), що робить оновлення ваг неможливим.\n",
        "\n",
        "![](https://editor.analyticsvidhya.com/uploads/27889vaegp.png)\n",
        "\n",
        "У логістичній регресії $ z = x \\cdot w + b $. Якщо ваги $w, b$ - великі, значення $z$ також буде великим, і сигмоїда перейде в насичену область, де градієнти дуже малі.\n",
        "\n",
        "Саме це сталося в нашій задачі, де великі випадкові значення ваг викликали насичення сигмоїдної функції. Це в свою чергу призводить до того, що під час зворотного поширення помилки (backpropagation) модель оновлює ваги дуже повільно або зовсім не оновлює. Це називається проблемою **зникнення градієнтів** (gradient vanishing problem).\n",
        "\n",
        "**Що ж робити?**\n",
        "Ініціювати ваги маленькими значеннями навколо нуля. Наприклад ми можемо просто в існуючій ініціалізації ваги розділити на 1000. Можна також використати інший спосіб ініціалізації вагів - інформація про це [тут](https://www.geeksforgeeks.org/initialize-weights-in-pytorch/).\n",
        "\n",
        "Як це робити - показую нижче. **Виконайте код та знову обчисліть передбачення, лосс і виведіть градієнти.**\n",
        "\n",
        "А я пишу пояснення, чому просто не зробити\n",
        "\n",
        "```\n",
        "w = torch.randn(1, 3, requires_grad=True)/1000\n",
        "b = torch.randn(1, requires_grad=True)/1000\n",
        "```\n",
        "\n",
        "Нам потрібно, аби тензори вагів були листовими (leaf tensors).\n",
        "\n",
        "1. **Що таке листовий тензор**\n",
        "Листовий тензор — це тензор, який був створений користувачем безпосередньо і з якого починається обчислювальний граф. Якщо такий тензор має `requires_grad=True`, PyTorch буде відслідковувати всі операції, виконані над ним, щоб правильно обчислювати градієнти під час навчання.\n",
        "\n",
        "2. **Чому ми використовуємо `w.data` замість звичайних операцій**\n",
        "Якщо ми просто виконали б операції, такі як `(w - 0.5) / 100`, ми б отримали **новий тензор**, який вже не був би листовим тензором, оскільки ці операції створюють **новий** тензор, а не модифікують існуючий.\n",
        "\n",
        "  Проте, щоб залишити наші тензори ваги `w` та зміщення `b` листовими і продовжити можливість відстеження градієнтів під час тренування, ми використовуємо атрибут `.data`. Цей атрибут дозволяє **виконувати операції in-place (прямо на існуючому тензорі)** без зміни самого об'єкта тензора. Отже, тензор залишається листовим, і PyTorch може коректно обчислювати його градієнти.\n",
        "\n",
        "3. **Чому важливо залишити тензор листовим**\n",
        "Якщо тензор більше не є листовим (наприклад, через проведення операцій, що створюють нові тензори), ви не зможете отримати градієнти за допомогою `w.grad` чи `b.grad` після виклику `loss.backward()`. Це може призвести до втрати можливості оновлення параметрів під час тренування моделі. В нашому випадку ми хочемо, щоб тензори `w` та `b` накопичували градієнти, тому вони повинні залишатись листовими.\n",
        "\n",
        "**Висновок:**\n",
        "Ми використовуємо `.data`, щоб виконати операції зміни значень на ваги і зміщення **in-place**, залишаючи їх листовими тензорами, які можуть накопичувати градієнти під час навчання. Це дозволяє коректно працювати механізму зворотного поширення помилки (backpropagation) і оновлювати ваги моделі."
      ],
      "metadata": {
        "id": "nDN1t1RujQsK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Виконайте код та знову обчисліть передбачення, лосс і знайдіть градієнти та виведіть всі ці тензори на екран."
      ],
      "metadata": {
        "id": "rOPSQyttpVjO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.random.manual_seed(1)\n",
        "w = torch.randn(1, 3, requires_grad=True)  # Листовий тензор\n",
        "b = torch.randn(1, requires_grad=True)     # Листовий тензор\n",
        "\n",
        "# in-place операції\n",
        "w.data = w.data / 1000\n",
        "b.data = b.data / 1000"
      ],
      "metadata": {
        "id": "-EBOJ3tsnRaD"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = model(inputs)\n",
        "print(preds)"
      ],
      "metadata": {
        "id": "-JwXiSpX6orh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41a858d3-5f2f-4ea8-af3c-f092ad12b920"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.5174],\n",
            "        [0.5220],\n",
            "        [0.5244],\n",
            "        [0.5204],\n",
            "        [0.5190]], grad_fn=<SigmoidBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = binary_cross_entropy(preds, targets)\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPhiK1-6sFyY",
        "outputId": "1c7b148f-5457-4e83-befe-40bd87d30586"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.6829, grad_fn=<MeanBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss.backward()\n",
        "print(w.grad)\n",
        "print(b.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjP0_GOmsHQj",
        "outputId": "a6aeb221-0f60-4b36-e580-d8b0cd115e0c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ -5.4417, -18.9853, -10.0682]])\n",
            "tensor([-0.0794])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Напишіть алгоритм градієнтного спуску, який буде навчати модель з використанням написаних раніше функцій і виконуючи оновлення ваг. Алгоритм має включати наступні кроки:\n",
        "\n",
        "  1. Генерація прогнозів\n",
        "  2. Обчислення втрат\n",
        "  3. Обчислення градієнтів (gradients) loss-фукнції відносно ваг і зсувів\n",
        "  4. Налаштування ваг шляхом віднімання невеликої величини, пропорційної градієнту (`learning_rate` домножений на градієнт)\n",
        "  5. Скидання градієнтів на нуль\n",
        "\n",
        "Виконайте градієнтний спуск протягом 1000 епох, обчисліть фінальні передбачення і проаналізуйте, чи вони точні?"
      ],
      "metadata": {
        "id": "RCdi44IT334o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Гіперпараметри\n",
        "learning_rate = 1e-5\n",
        "epochs = 1000\n",
        "\n",
        "# Цикл навчання\n",
        "for epoch in range(epochs):\n",
        "    # 1. Генерація прогнозів\n",
        "    preds = model(inputs)\n",
        "\n",
        "    # 2. Обчислення втрат\n",
        "    loss = binary_cross_entropy(preds, targets)\n",
        "\n",
        "    # 3. Обчислення градієнтів\n",
        "    loss.backward()\n",
        "\n",
        "    # 4. Налаштування ваг\n",
        "    with torch.no_grad():\n",
        "        w -= w.grad * learning_rate\n",
        "        b -= b.grad * learning_rate\n",
        "\n",
        "    # 5. Скидання градієнтів\n",
        "    w.grad.zero_()\n",
        "    b.grad.zero_()\n",
        "\n",
        "    # Виведення втрат кожні 100 епох\n",
        "    if (epoch + 1) % 100 == 0:\n",
        "        print(f'Epoch {epoch+1}: loss = {loss.item():.4f}')\n",
        "\n",
        "# Фінальні передбачення\n",
        "final_preds = model(inputs)"
      ],
      "metadata": {
        "id": "mObHPyE06qsO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69de425e-2945-4da8-e9f0-c60ba8121784"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 100: loss = 0.5626\n",
            "Epoch 200: loss = 0.5071\n",
            "Epoch 300: loss = 0.4650\n",
            "Epoch 400: loss = 0.4327\n",
            "Epoch 500: loss = 0.4073\n",
            "Epoch 600: loss = 0.3871\n",
            "Epoch 700: loss = 0.3706\n",
            "Epoch 800: loss = 0.3570\n",
            "Epoch 900: loss = 0.3455\n",
            "Epoch 1000: loss = 0.3358\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "targets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_mP9TCEUscZJ",
        "outputId": "2aab25a4-31df-4ec7-f082-d41fb220483d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.],\n",
              "        [1.],\n",
              "        [1.],\n",
              "        [0.],\n",
              "        [1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Спостереження:**\n",
        "\n",
        "Втрати значно зменшились loss = 0.2 і передбачення виглядають непогано"
      ],
      "metadata": {
        "id": "E808T0d5shwD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Секція 2. Створення лог регресії з використанням функціоналу `torch.nn`.**\n",
        "\n",
        "Давайте повторно реалізуємо ту ж модель, використовуючи деякі вбудовані функції та класи з PyTorch.\n",
        "\n",
        "Даних у нас буде побільше - тож, визначаємо нові масиви."
      ],
      "metadata": {
        "id": "fuRhlyF9qAia"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Вхідні дані (temp, rainfall, humidity)\n",
        "inputs = np.array([[73, 67, 43],\n",
        "                   [91, 88, 64],\n",
        "                   [87, 134, 58],\n",
        "                   [102, 43, 37],\n",
        "                   [69, 96, 70],\n",
        "                   [73, 67, 43],\n",
        "                   [91, 88, 64],\n",
        "                   [87, 134, 58],\n",
        "                   [102, 43, 37],\n",
        "                   [69, 96, 70],\n",
        "                   [73, 67, 43],\n",
        "                   [91, 88, 64],\n",
        "                   [87, 134, 58],\n",
        "                   [102, 43, 37],\n",
        "                   [69, 96, 70]], dtype='float32')\n",
        "\n",
        "# Таргети (apples > 80)\n",
        "targets = np.array([[0],\n",
        "                    [1],\n",
        "                    [1],\n",
        "                    [0],\n",
        "                    [1],\n",
        "                    [0],\n",
        "                    [1],\n",
        "                    [1],\n",
        "                    [0],\n",
        "                    [1],\n",
        "                    [0],\n",
        "                    [1],\n",
        "                    [1],\n",
        "                    [0],\n",
        "                    [1]], dtype='float32')"
      ],
      "metadata": {
        "id": "IX8Bhm74rV4M"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Завантажте вхідні дані та мітки в PyTorch тензори та з них створіть датасет, який поєднує вхідні дані з мітками, використовуючи клас `TensorDataset`. Виведіть перші 3 елементи в датасеті.\n",
        "\n"
      ],
      "metadata": {
        "id": "7X2dV30KtAPu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Імпортуємо tensor dataset & data loader\n",
        "from torch.utils.data import TensorDataset, DataLoader"
      ],
      "metadata": {
        "id": "7iRislBosqxf"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = torch.from_numpy(inputs)\n",
        "targets = torch.from_numpy(targets)"
      ],
      "metadata": {
        "id": "chrvMfBs6vjo"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Визначаємо dataset\n",
        "train_ds = TensorDataset(inputs, targets)\n",
        "train_ds[0:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yuHj7aggssfU",
        "outputId": "e3b1dc8d-9ad5-4de3-c8be-5ad4871a0713"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 73.,  67.,  43.],\n",
              "         [ 91.,  88.,  64.],\n",
              "         [ 87., 134.,  58.]]),\n",
              " tensor([[0.],\n",
              "         [1.],\n",
              "         [1.]]))"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Визначте data loader з класом **DataLoader** для підготовленого датасету `train_ds`, встановіть розмір батчу на 5 та увімкніть перемішування даних для ефективного навчання моделі. Виведіть перший елемент в дата лоадері."
      ],
      "metadata": {
        "id": "4nMFaa8suOd3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Визначаємо data loader\n",
        "batch_size = 5\n",
        "train_dl = DataLoader(train_ds, batch_size, shuffle=True)\n",
        "next(iter(train_dl))"
      ],
      "metadata": {
        "id": "ZCsRo5Mx6wEI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f370ac7c-dfa9-4ee1-e85a-3b868ba6137b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[ 73.,  67.,  43.],\n",
              "         [ 91.,  88.,  64.],\n",
              "         [102.,  43.,  37.],\n",
              "         [ 69.,  96.,  70.],\n",
              "         [102.,  43.,  37.]]),\n",
              " tensor([[0.],\n",
              "         [1.],\n",
              "         [0.],\n",
              "         [1.],\n",
              "         [0.]])]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. Створіть клас `LogReg` для логістичної регресії, наслідуючи модуль `torch.nn.Module` за прикладом в лекції (в частині про FeedForward мережі).\n",
        "\n",
        "  У нас модель складається з лінійної комбінації вхідних значень і застосування фукнції сигмоїда. Тож, нейромережа буде складатись з лінійного шару `nn.Linear` і використання активації `nn.Sigmid`. У створеному класі мають бути реалізовані методи `__init__` з ініціалізацією шарів і метод `forward` для виконання прямого проходу моделі через лінійний шар і функцію активації.\n",
        "\n",
        "  Створіть екземпляр класу `LogReg` в змінній `model`."
      ],
      "metadata": {
        "id": "ymcQOo_hum6I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "EyAwhTBW6xxz"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LogReg(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LogReg, self).__init__()\n",
        "        self.linear = nn.Linear(3, 1)  # 3 input features, 1 output\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear(x)\n",
        "        return torch.sigmoid(x)  # Apply sigmoid activation\n",
        "\n",
        "model = LogReg()\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CfxQgI-Msx7c",
        "outputId": "9b9a97f4-5821-4be0-857c-10835c44e8f7"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogReg(\n",
              "  (linear): Linear(in_features=3, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. Задайте оптимізатор `Stockastic Gradient Descent` в змінній `opt` для навчання моделі логістичної регресії. А також визначіть в змінній `loss` функцію втрат `binary_cross_entropy` з модуля `torch.nn.functional` для обчислення втрат моделі. Обчисліть втрати для поточних передбачень і міток, а потім виведіть їх. Зробіть висновок, чи моделі вдалось навчитись?"
      ],
      "metadata": {
        "id": "RflV7xeVyoJy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the optimizer\n",
        "opt = torch.optim.SGD(model.parameters(), lr=1e-5)  # Stochastic Gradient Descent\n",
        "\n",
        "# Define the loss function\n",
        "loss_fn = F.binary_cross_entropy\n",
        "\n",
        "# Get predictions\n",
        "preds = model(inputs)\n",
        "\n",
        "# Calculate the loss\n",
        "loss = loss_fn(preds, targets)\n",
        "\n",
        "# Print the loss\n",
        "print(\"Initial Loss:\", loss.item())"
      ],
      "metadata": {
        "id": "3QCATPU_6yfa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f15e364-280a-4727-ddf6-16fc4f787c6e"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Loss: 7.631152629852295\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Спостереження:**\n",
        "\n",
        "Модель ще не навчилася розрізняти класи, бо ще не пройшла тренування.\n",
        "Втрати дорівнюють 7.63.\n",
        "\n",
        "Щоб виправити ситуацію, треба навчити модель."
      ],
      "metadata": {
        "id": "w7mvEdass40_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "11. Візьміть з лекції функцію для тренування моделі з відстеженням значень втрат і навчіть щойно визначену модель на 1000 епохах. Виведіть після цього графік зміни loss, фінальні передбачення і значення таргетів."
      ],
      "metadata": {
        "id": "ch-WrYnKzMzq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "17HRNlX_wI1f"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# === 1. Генерация простых данных (2D точки) ===\n",
        "torch.manual_seed(0)\n",
        "# 10 точек класса 0, 10 точек класса 1\n",
        "x0 = torch.randn(10, 2) - 2     # класс 0\n",
        "x1 = torch.randn(10, 2) + 2     # класс 1\n",
        "X = torch.cat([x0, x1], dim=0)\n",
        "y = torch.cat([torch.zeros(10,1), torch.ones(10,1)], dim=0)\n",
        "\n",
        "# === 2. DataLoader ===\n",
        "train_ds = torch.utils.data.TensorDataset(X, y)\n",
        "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=5, shuffle=True)\n",
        "\n",
        "# === 3. Модель (2 слоя, ReLU + Sigmoid) ===\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(2, 8),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(8, 1),\n",
        "    nn.Sigmoid()\n",
        ")\n",
        "\n",
        "# === 4. Оптимизатор и функция потерь ===\n",
        "opt = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "loss_fn = F.binary_cross_entropy\n",
        "\n",
        "# === 5. Функция обучения с логом потерь ===\n",
        "def fit_return_loss(num_epochs, model, loss_fn, opt, train_dl):\n",
        "    losses = []\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0\n",
        "        for xb, yb in train_dl:\n",
        "            pred = model(xb)\n",
        "            loss = loss_fn(pred, yb)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            opt.zero_grad()\n",
        "            total_loss += loss.item()\n",
        "        avg_loss = total_loss / len(train_dl)\n",
        "        losses.append(avg_loss)\n",
        "        if (epoch + 1) % 200 == 0:\n",
        "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}')\n",
        "    return losses\n",
        "\n",
        "# === 6. Обучение ===\n",
        "losses = fit_return_loss(1000, model, loss_fn, opt, train_dl)\n",
        "\n",
        "plt.plot(losses)\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training loss\")\n",
        "plt.show()\n",
        "\n",
        "# === 7. Предсказания ===\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    final_probs = model(X)\n",
        "    final_preds = (final_probs >= 0.5).float()\n",
        "\n",
        "acc = (final_preds.eq(y)).float().mean().item()\n",
        "tp = ((final_preds==1) & (y==1)).sum().item()\n",
        "tn = ((final_preds==0) & (y==0)).sum().item()\n",
        "fp = ((final_preds==1) & (y==0)).sum().item()\n",
        "fn = ((final_preds==0) & (y==1)).sum().item()\n",
        "\n",
        "print(\"\\nFinal probabilities:\\n\", torch.round(final_probs * 1000) / 1000)\n",
        "print(\"\\nFinal predictions (>=0.5):\\n\", final_preds)\n",
        "print(\"\\nTargets:\\n\", y)\n",
        "print(f\"\\nAccuracy: {acc:.3f}\")\n",
        "print(f\"TP={tp}, TN={tn}, FP={fp}, FN={fn}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0zF5AOxewQRW",
        "outputId": "5d7f1c90-2bfd-4fb8-a58e-2c63a1664d45"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [200/1000], Loss: 0.0300\n",
            "Epoch [400/1000], Loss: 0.0122\n",
            "Epoch [600/1000], Loss: 0.0072\n",
            "Epoch [800/1000], Loss: 0.0050\n",
            "Epoch [1000/1000], Loss: 0.0038\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAQi1JREFUeJzt3Xl8VPW9//H3zCQz2RcISVjCIvADAQEFwQiKvUZRqYrLvWhRkLZYt4o32ttSKyiWQtUit2rBpWBdsfYqWqtYjFI3BAUCioBQBAKYhBCzk23m+/sjmYGBsIWZOZPJ6/l4nEcm3/M9M585reT9+H6/5xybMcYIAAAgQtitLgAAACCQCDcAACCiEG4AAEBEIdwAAICIQrgBAAARhXADAAAiCuEGAABEFMINAACIKIQbAAAQUQg3AELmpptuUs+ePVt17P333y+bzRbYgk7QqdQNIPQINwBks9lOaFuxYoXVpQLAcdl4thSAF154we/35557TsuXL9fzzz/v137RRRcpIyOj1Z/T0NAgj8cjl8t10sc2NjaqsbFRMTExrf781rrpppu0YsUK7dixI+SfDeDkRVldAADr3XDDDX6/f/bZZ1q+fPkR7YerqalRXFzcCX9OdHR0q+qTpKioKEVF8U8WgONjWgrACbngggs0aNAgrVmzRueff77i4uL061//WpL0xhtvaNy4cerSpYtcLpd69+6tBx98UG632+89Dl+7smPHDtlsNj3yyCN66qmn1Lt3b7lcLp199tn6/PPP/Y5tac2NzWbTHXfcoaVLl2rQoEFyuVwaOHCgli1bdkT9K1as0PDhwxUTE6PevXvrySefPKV1PNXV1br77ruVlZUll8ulfv366ZFHHtHhg+HLly/X6NGjlZKSooSEBPXr18933rwee+wxDRw4UHFxcUpNTdXw4cP10ksvtaouAIzcADgJ+/fv16WXXqrrrrtON9xwg2+K6tlnn1VCQoJyc3OVkJCg999/XzNmzFBFRYUefvjh477vSy+9pMrKSv3sZz+TzWbTQw89pKuvvlrbt28/7mjPxx9/rNdee0233XabEhMT9cc//lHXXHONdu3apY4dO0qS1q1bp0suuUSdO3fWAw88ILfbrVmzZqlTp06tOg/GGF1xxRX64IMP9JOf/ERDhw7Vu+++q1/84hfas2ePHn30UUnSxo0b9cMf/lCDBw/WrFmz5HK5tG3bNn3yySe+93r66ad155136tprr9W0adNUW1urDRs2aNWqVfrRj37UqvqAds8AwGFuv/12c/g/D2PGjDGSzMKFC4/oX1NTc0Tbz372MxMXF2dqa2t9bZMnTzY9evTw/f7tt98aSaZjx46mtLTU1/7GG28YSebvf/+7r23mzJlH1CTJOJ1Os23bNl/b+vXrjSTz2GOP+douv/xyExcXZ/bs2eNr27p1q4mKijriPVtyeN1Lly41ksxvf/tbv37XXnutsdlsvnoeffRRI8ns27fvqO995ZVXmoEDBx63BgAnjmkpACfM5XJpypQpR7THxsb6XldWVqqkpETnnXeeampqtHnz5uO+74QJE5Samur7/bzzzpMkbd++/bjH5uTkqHfv3r7fBw8erKSkJN+xbrdb7733nsaPH68uXbr4+vXp00eXXnrpcd+/JW+//bYcDofuvPNOv/a7775bxhi98847kqSUlBRJTdN2Ho+nxfdKSUnR7t27j5iGA9B6hBsAJ6xr165yOp1HtG/cuFFXXXWVkpOTlZSUpE6dOvkWI5eXlx/3fbt37+73uzfofP/99yd9rPd477HFxcU6cOCA+vTpc0S/ltpOxM6dO9WlSxclJib6tZ9++um+/VJTaBs1apR++tOfKiMjQ9ddd53++te/+gWdX/7yl0pISNCIESPUt29f3X777X7TVgBOHuEGwAk7dITGq6ysTGPGjNH69es1a9Ys/f3vf9fy5cv1+9//XpKOOmJxKIfD0WK7OYE7VZzKscEWGxurDz/8UO+9955uvPFGbdiwQRMmTNBFF13kW2x9+umna8uWLVqyZIlGjx6t//u//9Po0aM1c+ZMi6sH2i7CDYBTsmLFCu3fv1/PPvuspk2bph/+8IfKycnxm2ayUnp6umJiYrRt27Yj9rXUdiJ69OihvXv3qrKy0q/dOwXXo0cPX5vdbteFF16oefPm6euvv9bs2bP1/vvv64MPPvD1iY+P14QJE7R48WLt2rVL48aN0+zZs1VbW9uq+oD2jnAD4JR4R04OHSmpr6/Xn/70J6tK8uNwOJSTk6OlS5dq7969vvZt27b51sacrMsuu0xut1uPP/64X/ujjz4qm83mW8tTWlp6xLFDhw6VJNXV1UlqugLtUE6nUwMGDJAxRg0NDa2qD2jvuBQcwCk599xzlZqaqsmTJ+vOO++UzWbT888/HxbTQl7333+//vnPf2rUqFG69dZbfcFk0KBBys/PP+n3u/zyy/WDH/xA9957r3bs2KEhQ4bon//8p9544w3dddddvgXOs2bN0ocffqhx48apR48eKi4u1p/+9Cd169ZNo0ePliRdfPHFyszM1KhRo5SRkaFNmzbp8ccf17hx445Y0wPgxBBuAJySjh076q233tLdd9+t3/zmN0pNTdUNN9ygCy+8UGPHjrW6PEnSsGHD9M477+iee+7Rfffdp6ysLM2aNUubNm06oau5Dme32/Xmm29qxowZeuWVV7R48WL17NlTDz/8sO6++25fvyuuuEI7duzQokWLVFJSorS0NI0ZM0YPPPCAkpOTJUk/+9nP9OKLL2revHmqqqpSt27ddOedd+o3v/lNwL4/0N7wbCkA7db48eO1ceNGbd261epSAAQQa24AtAsHDhzw+33r1q16++23dcEFF1hTEICgYeQGQLvQuXNn3XTTTTrttNO0c+dOLViwQHV1dVq3bp369u1rdXkAAog1NwDahUsuuUQvv/yyCgsL5XK5lJ2drd/97ncEGyACMXIDAAAiCmtuAABARCHcAACAiNLu1tx4PB7t3btXiYmJstlsVpcDAABOgDFGlZWV6tKli+z244zNmDDw+OOPmx49ehiXy2VGjBhhVq1addS+ixcvNpL8NpfLdcKfVVBQcMTxbGxsbGxsbG1jKygoOO7festHbl555RXl5uZq4cKFGjlypObPn6+xY8dqy5YtSk9Pb/GYpKQkbdmyxff7yYzAeG9nXlBQoKSkpFMrHgAAhERFRYWysrJO6LEkloebefPmaerUqZoyZYokaeHChfrHP/6hRYsW6Ve/+lWLx9hsNmVmZrbq87xBKCkpiXADAEAbcyIDGpYuKK6vr9eaNWuUk5Pja7Pb7crJydHKlSuPelxVVZV69OihrKwsXXnlldq4ceNR+9bV1amiosJvAwAAkcvScFNSUiK3262MjAy/9oyMDBUWFrZ4TL9+/bRo0SK98cYbeuGFF+TxeHTuuedq9+7dLfafM2eOkpOTfVtWVlbAvwcAAAgfbe5S8OzsbE2aNElDhw7VmDFj9Nprr6lTp0568sknW+w/ffp0lZeX+7aCgoIQVwwAAELJ0jU3aWlpcjgcKioq8msvKio64TU10dHROvPMM7Vt27YW97tcLrlcrlOuFQAAtA2Wjtw4nU4NGzZMeXl5vjaPx6O8vDxlZ2ef0Hu43W59+eWX6ty5c7DKBAAAbYjlV0vl5uZq8uTJGj58uEaMGKH58+erurrad/XUpEmT1LVrV82ZM0eSNGvWLJ1zzjnq06ePysrK9PDDD2vnzp366U9/auXXAAAAYcLycDNhwgTt27dPM2bMUGFhoYYOHaply5b5Fhnv2rXL706E33//vaZOnarCwkKlpqZq2LBh+vTTTzVgwACrvgIAAAgj7e6p4BUVFUpOTlZ5eTn3uQEAoI04mb/fbe5qKQAAgGMh3AAAgIhCuAEAABGFcAMAACKK5VdLRYr6Ro9KqupkJHVNibW6HAAA2i1GbgIkv6BM5859Xzc+s8rqUgAAaNcINwESE910Kmsb3BZXAgBA+0a4CRBXlEOSVNfosbgSAADaN8JNgDByAwBAeCDcBAgjNwAAhAfCTYB4R24aPUaNbgIOAABWIdwEiHfkRmL0BgAAKxFuAsQVdfBUsu4GAADrEG4CxG63yeloXlTMyA0AAJYh3ASQq3ndTR0jNwAAWIZwE0DedTe1DYzcAABgFcJNAHmvmKprZOQGAACrEG4CKCaakRsAAKxGuAkg7xVTjNwAAGAdwk0AMXIDAID1CDcBxMgNAADWI9wEkHfkpo6RGwAALEO4CSBGbgAAsB7hJoBYcwMAgPUINwHEyA0AANYj3AQQIzcAAFiPcBNAjNwAAGA9wk0AuRi5AQDAcoSbAGLkBgAA6xFuAog1NwAAWI9wE0DekZvaBkZuAACwCuEmgHx3KG5k5AYAAKsQbgKIkRsAAKxHuAkgRm4AALAe4SaAGLkBAMB6hJsA8o7c1DNyAwCAZQg3ARQTzcgNAABWI9wEkCuKNTcAAFiNcBNAjNwAAGA9wk0AMXIDAID1CDcB5B25afQYNboJOAAAWIFwE0DekRuJ0RsAAKxCuAkg731uJNbdAABgFcJNANntNjkdTaeUkRsAAKxBuAkwF1dMAQBgKcJNgHHFFAAA1iLcBJj3iqkDjNwAAGAJwk2AxTY/X6q2nnADAIAVCDcBFudsCjc1hBsAACxBuAmw2OZww7QUAADWINwEWJwzSpJ0gJEbAAAsQbgJMO+am5r6RosrAQCgfSLcBJh3WqqGaSkAACxBuAkw74JipqUAALAG4SbAYgk3AABYinATYHHRTQuKmZYCAMAahJsAY1oKAABrEW4CLMbJ1VIAAFiJcBNgcdHcoRgAACuFRbh54okn1LNnT8XExGjkyJFavXr1CR23ZMkS2Ww2jR8/PrgFngTvtFQta24AALCE5eHmlVdeUW5urmbOnKm1a9dqyJAhGjt2rIqLi4953I4dO3TPPffovPPOC1GlJyaWZ0sBAGApy8PNvHnzNHXqVE2ZMkUDBgzQwoULFRcXp0WLFh31GLfbrYkTJ+qBBx7QaaedFsJqj4/HLwAAYC1Lw019fb3WrFmjnJwcX5vdbldOTo5Wrlx51ONmzZql9PR0/eQnPwlFmSeFp4IDAGCtKCs/vKSkRG63WxkZGX7tGRkZ2rx5c4vHfPzxx/rzn/+s/Pz8E/qMuro61dXV+X6vqKhodb0nIoZnSwEAYCnLp6VORmVlpW688UY9/fTTSktLO6Fj5syZo+TkZN+WlZUV1BoPLij2BPVzAABAyywduUlLS5PD4VBRUZFfe1FRkTIzM4/o/+9//1s7duzQ5Zdf7mvzeJpCRFRUlLZs2aLevXv7HTN9+nTl5ub6fq+oqAhqwPGGm3q3R41uj6IcbSo/AgDQ5ln6l9fpdGrYsGHKy8vztXk8HuXl5Sk7O/uI/v3799eXX36p/Px833bFFVfoBz/4gfLz81sMLS6XS0lJSX5bMHmvlpJ4BAMAAFawdORGknJzczV58mQNHz5cI0aM0Pz581VdXa0pU6ZIkiZNmqSuXbtqzpw5iomJ0aBBg/yOT0lJkaQj2q3idNjlsNvk9hgdqHcrKSba6pIAAGhXLA83EyZM0L59+zRjxgwVFhZq6NChWrZsmW+R8a5du2S3t52pHZvNprhohyrrGrliCgAAC9iMMcbqIkKpoqJCycnJKi8vD9oU1dmz39O+yjr9487RGtglOSifAQBAe3Iyf7/bzpBIG8IjGAAAsA7hJghieXgmAACWIdwEAXcpBgDAOoSbIOD5UgAAWIdwEwQ8GRwAAOsQboLAu+bmAAuKAQAIOcJNEHjX3Bzg4ZkAAIQc4SYImJYCAMA6hJsg4GopAACsQ7gJAu/VUjVMSwEAEHKEmyCIbx65qWbkBgCAkCPcBEG8q3nkpo6RGwAAQo1wEwTecMPIDQAAoUe4CYKDC4oZuQEAINQIN0FwcFqKkRsAAEKNcBMEcb4FxYzcAAAQaoSbIIhvvhS8mpEbAABCjnATBHGugyM3xhiLqwEAoH0h3ASBd+TGGKm2wWNxNQAAtC+EmyCIjXbIZmt6zbobAABCi3ATBHa7TXHRzZeDs+4GAICQItwESZzvRn6M3AAAEEqEmyCJ50Z+AABYgnATJN4ng1cxLQUAQEgRboIk3uVdc8PIDQAAoUS4CRLvyA0PzwQAILQIN0GS4H2+FGtuAAAIKcJNkHifL1XFtBQAACFFuAmShJjmBcW1hBsAAEKJcBMkiTHRkqRKwg0AACFFuAmSpOaRm8raBosrAQCgfSHcBIl3QTEjNwAAhBbhJkiYlgIAwBqEmyBJbJ6WqmBaCgCAkCLcBEliDNNSAABYgXATJAenpRi5AQAglAg3QeK9WqqqrlHGGIurAQCg/SDcBIl35MZjeL4UAAChRLgJkphou6LsNklMTQEAEEqEmyCx2WwsKgYAwAKEmyBiUTEAAKFHuAmig/e6YeQGAIBQIdwEUSJPBgcAIOQIN0HEIxgAAAg9wk0QJfJkcAAAQo5wE0SJPBkcAICQI9wEEVdLAQAQeoSbIOI+NwAAhB7hJoi8IzdcCg4AQOgQboKIBcUAAIQe4SaImJYCACD0CDdBlBTrnZZi5AYAgFAh3ARRSnO4Ka8h3AAAECqEmyBKbg43lXWNcnuMxdUAANA+EG6CyDstJUkVBxi9AQAgFAg3QRTtsCuh+S7FZYQbAABCgnATZN6pqXLCDQAAIUG4CTLv1FRZTb3FlQAA0D4QboIshZEbAABCinATZN5pKRYUAwAQGmERbp544gn17NlTMTExGjlypFavXn3Uvq+99pqGDx+ulJQUxcfHa+jQoXr++edDWO3JSfZNSxFuAAAIBcvDzSuvvKLc3FzNnDlTa9eu1ZAhQzR27FgVFxe32L9Dhw669957tXLlSm3YsEFTpkzRlClT9O6774a48hOTEse0FAAAoWR5uJk3b56mTp2qKVOmaMCAAVq4cKHi4uK0aNGiFvtfcMEFuuqqq3T66aerd+/emjZtmgYPHqyPP/44xJWfmCTW3AAAEFKWhpv6+nqtWbNGOTk5vja73a6cnBytXLnyuMcbY5SXl6ctW7bo/PPPb7FPXV2dKioq/LZQ8k1LEW4AAAgJS8NNSUmJ3G63MjIy/NozMjJUWFh41OPKy8uVkJAgp9OpcePG6bHHHtNFF13UYt85c+YoOTnZt2VlZQX0OxwP01IAAISW5dNSrZGYmKj8/Hx9/vnnmj17tnJzc7VixYoW+06fPl3l5eW+raCgIKS1crUUAAChFWXlh6elpcnhcKioqMivvaioSJmZmUc9zm63q0+fPpKkoUOHatOmTZozZ44uuOCCI/q6XC65XK6A1n0yuFoKAIDQsnTkxul0atiwYcrLy/O1eTwe5eXlKTs7+4Tfx+PxqK6uLhglnrKUWKckpqUAAAgVS0duJCk3N1eTJ0/W8OHDNWLECM2fP1/V1dWaMmWKJGnSpEnq2rWr5syZI6lpDc3w4cPVu3dv1dXV6e2339bzzz+vBQsWWPk1jso7cnOgwa26RrdcUQ6LKwIAILJZHm4mTJigffv2acaMGSosLNTQoUO1bNky3yLjXbt2yW4/OMBUXV2t2267Tbt371ZsbKz69++vF154QRMmTLDqKxxTYkyUbDbJmKbRm/REwg0AAMFkM8YYq4sIpYqKCiUnJ6u8vFxJSUkh+cwhD/xT5QcatPy/z1ffjMSQfCYAAJHkZP5+t8mrpdqa1ObLwb9nUTEAAEFHuAmBDvFNi4pLq8Nz0TMAAJGEcBMCB8MNIzcAAAQb4SYEGLkBACB0CDch0CG+6SaC+6vrLa4EAIDIR7gJgQ7xzQuKCTcAAAQd4SYEGLkBACB0CDch0NG35oZwAwBAsBFuQiCVcAMAQMgQbkLg0JGbdnZDaAAAQo5wEwLeS8HrGj2qqXdbXA0AAJGNcBMCcU6HnFFNp5qpKQAAgotwEwI2m41FxQAAhAjhJkQ6EG4AAAgJwk2IeMMN97oBACC4CDch4g033KUYAIDgItyEiDfclPDwTAAAgopwEyJpCc2PYKhi5AYAgGAi3IRIp+Zws6+SkRsAAIKJcBMiaYnN01JVhBsAAIKJcBMinRJiJBFuAAAItlaFm4KCAu3evdv3++rVq3XXXXfpqaeeClhhkebgyE29PB6eLwUAQLC0Ktz86Ec/0gcffCBJKiws1EUXXaTVq1fr3nvv1axZswJaYKToGN+05sbtMSo70GBxNQAARK5WhZuvvvpKI0aMkCT99a9/1aBBg/Tpp5/qxRdf1LPPPhvI+iKGM8qulLhoSSwqBgAgmFoVbhoaGuRyNY1EvPfee7riiiskSf3799d3330XuOoijPdycNbdAAAQPK0KNwMHDtTChQv10Ucfafny5brkkkskSXv37lXHjh0DWmAk6US4AQAg6FoVbn7/+9/rySef1AUXXKDrr79eQ4YMkSS9+eabvukqHCktkXvdAAAQbFGtOeiCCy5QSUmJKioqlJqa6mu/+eabFRcXF7DiIo3vRn6M3AAAEDStGrk5cOCA6urqfMFm586dmj9/vrZs2aL09PSAFhhJfJeDV/IIBgAAgqVV4ebKK6/Uc889J0kqKyvTyJEj9Yc//EHjx4/XggULAlpgJElj5AYAgKBrVbhZu3atzjvvPEnS3/72N2VkZGjnzp167rnn9Mc//jGgBUaSTs1rbkpYcwMAQNC0KtzU1NQoMTFRkvTPf/5TV199tex2u8455xzt3LkzoAVGEu+am2LCDQAAQdOqcNOnTx8tXbpUBQUFevfdd3XxxRdLkoqLi5WUlBTQAiNJZnLT86X2V9epvtFjcTUAAESmVoWbGTNm6J577lHPnj01YsQIZWdnS2oaxTnzzDMDWmAk6RjvlNNhlzFSUUWt1eUAABCRWnUp+LXXXqvRo0fru+++893jRpIuvPBCXXXVVQErLtLYbDZlJsdoV2mNCitqldWBy+YBAAi0VoUbScrMzFRmZqbv6eDdunXjBn4nwBtu9pYdsLoUAAAiUqumpTwej2bNmqXk5GT16NFDPXr0UEpKih588EF5PKwlOZYuzetuCsuZlgIAIBhaNXJz77336s9//rPmzp2rUaNGSZI+/vhj3X///aqtrdXs2bMDWmQkyUyOlSR9R7gBACAoWhVu/vKXv+iZZ57xPQ1ckgYPHqyuXbvqtttuI9wcQ+fmkZvvypmWAgAgGFo1LVVaWqr+/fsf0d6/f3+VlpaeclGRrDPTUgAABFWrws2QIUP0+OOPH9H++OOPa/DgwadcVCTrzLQUAABB1appqYceekjjxo3Te++957vHzcqVK1VQUKC33347oAVGGu+N/PZVNd3IzxnVqnwJAACOolV/WceMGaNvvvlGV111lcrKylRWVqarr75aGzdu1PPPPx/oGiPKoTfyK65k9AYAgECzGWNMoN5s/fr1Ouuss+R2uwP1lgFXUVGh5ORklZeXW/aoiPMeel8FpQf0t1uyNbxnB0tqAACgLTmZv9/MiVjAu+5mL+tuAAAIOMKNBQ5eMcXl4AAABBrhxgLeRcV7yxi5AQAg0E7qaqmrr776mPvLyspOpZZ2o4vvcnBGbgAACLSTCjfJycnH3T9p0qRTKqg96JLSFG728PBMAAAC7qTCzeLFi4NVR7uS1aEp3BSUEm4AAAg01txYICs1TpJUfqBBFbUNFlcDAEBkIdxYIN4VpQ7xTklSQWmNxdUAABBZCDcWyUplagoAgGAg3FikW4emqand3zNyAwBAIBFuLOJdd8O0FAAAgUW4sYjviqnvmZYCACCQCDcW6cbIDQAAQUG4sYh3QfHu7w8ogA9mBwCg3SPcWKRraqzsNulAg1v7KuusLgcAgIgRFuHmiSeeUM+ePRUTE6ORI0dq9erVR+379NNP67zzzlNqaqpSU1OVk5NzzP7hyhXlUNfm0ZtvS6otrgYAgMhhebh55ZVXlJubq5kzZ2rt2rUaMmSIxo4dq+Li4hb7r1ixQtdff70++OADrVy5UllZWbr44ou1Z8+eEFd+6nqlJUiSduwn3AAAECiWh5t58+Zp6tSpmjJligYMGKCFCxcqLi5OixYtarH/iy++qNtuu01Dhw5V//799cwzz8jj8SgvLy/ElZ+6Xh2bFhVvZ+QGAICAsTTc1NfXa82aNcrJyfG12e125eTkaOXKlSf0HjU1NWpoaFCHDh1a3F9XV6eKigq/LVz0SouXJH27j3ADAECgWBpuSkpK5Ha7lZGR4deekZGhwsLCE3qPX/7yl+rSpYtfQDrUnDlzlJyc7NuysrJOue5A6dWpaVqKNTcAAASO5dNSp2Lu3LlasmSJXn/9dcXExLTYZ/r06SovL/dtBQUFIa7y6E5rHrnZub9Gbg+XgwMAEAhRVn54WlqaHA6HioqK/NqLioqUmZl5zGMfeeQRzZ07V++9954GDx581H4ul0sulysg9QZal5RYOR121bs92lt2QFnNz5sCAACtZ+nIjdPp1LBhw/wWA3sXB2dnZx/1uIceekgPPvigli1bpuHDh4ei1KBw2G3qwaJiAAACyvJpqdzcXD399NP6y1/+ok2bNunWW29VdXW1pkyZIkmaNGmSpk+f7uv/+9//Xvfdd58WLVqknj17qrCwUIWFhaqqqrLqK5wS76LiHYQbAAACwtJpKUmaMGGC9u3bpxkzZqiwsFBDhw7VsmXLfIuMd+3aJbv9YAZbsGCB6uvrde211/q9z8yZM3X//feHsvSA8F0xRbgBACAgLA83knTHHXfojjvuaHHfihUr/H7fsWNH8AsKIW+4YVoKAIDAsHxaqr3zhpt/F7fNaTUAAMIN4cZi/y8jUZK0p+yAKmsbLK4GAIC2j3BjsdR4p9ITmy5V/6ao0uJqAABo+wg3YaB/5yRJ0uZCwg0AAKeKcBMG+mc2TU1tIdwAAHDKCDdhoF/zuhtGbgAAOHWEmzDQ75CRG2N4xhQAAKeCcBMG+qQnyGG3qfxAg4oq6qwuBwCANo1wEwZioh3q2fyMqc2FFRZXAwBA20a4CRP9M5uumGJRMQAAp4ZwEyb6ccUUAAABQbgJE95wwxVTAACcGsJNmPDe62bbvio1uj0WVwMAQNtFuAkTWalxinM6VN/o0Y79PCEcAIDWItyECbvdpr7czA8AgFNGuAkj/TNYVAwAwKki3ISRgV2bLgffsLvc4koAAGi7CDdhZEi3FEnS+t1lPIYBAIBWItyEkf6dE+V02FVW06BdpTVWlwMAQJtEuAkjriiHBnRpmprKLyizthgAANoowk2YGZqVIolwAwBAaxFuwow33Kwn3AAA0CqEmzAzpDncfLW3QvWN3KkYAICTRbgJMz07xik5Nlr1jR7udwMAQCsQbsKMzWbzjd7k7y6ztBYAANoiwk0YGtotWZKUv6vM2kIAAGiDCDdhyDtys27X99YWAgBAG0S4CUPDe3SQzSZtL6lWcWWt1eUAANCmEG7CUHJctPo1P0Tz828ZvQEA4GQQbsLUOad1lCSt+na/xZUAANC2EG7C1MheHSRJq7aXWlwJAABtC+EmTI1oDjdbiipVWl1vcTUAALQdhJsw1THBpb7pCZKk1d8yegMAwIki3ISxkac1T02x7gYAgBNGuAljI3s1Lypm3Q0AACeMcBPGvCM3mworVFbDuhsAAE4E4SaMpSfGqF9GooyRPtpaYnU5AAC0CYSbMHdBv06SpA+2FFtcCQAAbQPhJsxd0C9dkvSvLfvk8RiLqwEAIPwRbsLc8J6pSnBFaX91vb7cU251OQAAhD3CTZiLdtg1uk+aJKamAAA4EYSbNuAH/ZvW3azYss/iSgAACH+EmzbAu+5m/e4y7a+qs7gaAADCG+GmDchIitGAzkkyRvpwK6M3AAAcC+GmjfBeEv7+ZsINAADHQrhpIy48PUOS9P6mIh2od1tcDQAA4Ytw00ac1T1F3VJjVV3v1vJNRVaXAwBA2CLctBE2m01XndlVkrR03R6LqwEAIHwRbtqQK4c2hZt/fbOPq6YAADgKwk0b0ic9QYO7JcvtMXprw3dWlwMAQFgi3LQx45tHb15nagoAgBYRbtqYy4d0kcNuU35Bmb4tqba6HAAAwg7hpo3plOjyPWuKhcUAAByJcNMG+a6ayt8jY4zF1QAAEF4IN23QxQMzFOd0aOf+Gq0rKLO6HAAAwgrhpg2Kc0Zp7MBMSUxNAQBwOMJNGzW+eWrqrQ3fqcHtsbgaAADCB+GmjRrVu6PSElwqra7X+5uLrS4HAICwQbhpo6Icdl0zrGn05oXPdlpcDQAA4cPycPPEE0+oZ8+eiomJ0ciRI7V69eqj9t24caOuueYa9ezZUzabTfPnzw9doWHohpE9ZLNJH20t0fZ9VVaXAwBAWLA03LzyyivKzc3VzJkztXbtWg0ZMkRjx45VcXHL0yw1NTU67bTTNHfuXGVmZoa42vCT1SFO/9EvXZL0PKM3AABIsjjczJs3T1OnTtWUKVM0YMAALVy4UHFxcVq0aFGL/c8++2w9/PDDuu666+RyuUJcbXi6MbuHJOlvX+xWVV2jxdUAAGA9y8JNfX291qxZo5ycnIPF2O3KycnRypUrA/Y5dXV1qqio8Nsiyfl9O+m0tHhV1jXq+ZWM3gAAYFm4KSkpkdvtVkZGhl97RkaGCgsLA/Y5c+bMUXJysm/LysoK2HuHA7vdptt+0EeS9MxH21VTz+gNAKB9s3xBcbBNnz5d5eXlvq2goMDqkgLuyqFdlNUhVvur6/XSql1WlwMAgKUsCzdpaWlyOBwqKiryay8qKgroYmGXy6WkpCS/LdJEO+y67YKm0ZunPtyu2ga3xRUBAGAdy8KN0+nUsGHDlJeX52vzeDzKy8tTdna2VWW1Wdec1U1dkmNUXFmnv34ReaNTAACcKEunpXJzc/X000/rL3/5izZt2qRbb71V1dXVmjJliiRp0qRJmj59uq9/fX298vPzlZ+fr/r6eu3Zs0f5+fnatm2bVV8hbDij7Lrlgt6SpIUr/q36Rh7JAABon6Ks/PAJEyZo3759mjFjhgoLCzV06FAtW7bMt8h4165dstsP5q+9e/fqzDPP9P3+yCOP6JFHHtGYMWO0YsWKUJcfdv5reJYef3+b9pbX6rW1u3XdiO5WlwQAQMjZjDHG6iJCqaKiQsnJySovL4/I9TfPfLRdv/3HJmUmxej9e8YozmlpfgUAICBO5u93xF8t1d7ccE4PdU2JVWFFrZ76cLvV5QAAEHKEmwgTE+3Qry87XZL05L+267vyAxZXBABAaBFuItBlZ2Tq7J6pOtDg1sPLtlhdDgAAIUW4iUA2m033/XCAJOm1dXu0dtf3FlcEAEDoEG4i1OBuKbp2WDdJ0q9f+5JLwwEA7QbhJoL9+rLT1SHeqc2FlXr6IxYXAwDaB8JNBOsQ79SM5ump/83bqh0l1RZXBABA8BFuItyVQ7vovL5pqm/06H/+tkFuT7u6rREAoB0i3EQ4m82m2ePPULzTodU7SrVgBY+qAABENsJNO9C9Y5xmXTlIkvToe1u1jqunAAARjHDTTlx9VlddPqSL3B6jaUvyVVXXaHVJAAAEBeGmnbDZbPrt+EHqmhKrXaU1+p+/rVc7e6wYAKCdINy0I8mx0XrsR2cq2mHT218WauG/uDwcABB5CDftzFndU3X/FQMlSQ+/u1kffrPP4ooAAAgswk079KMR3XXd2VnyGOnnL6/TtuIqq0sCACBgCDftkM1m0wNXDtSZ3VNUfqBBkxetVlFFrdVlAQAQEISbdsoV5dAzk4arV1q89pQd0E2LP1dFbYPVZQEAcMoIN+1YxwSXnvvxCKUluLTpuwrd8vwa1Ta4rS4LAIBTQrhp57I6xOnZKWcr3unQp//er6nPfUHAAQC0aYQbaFDXZD0z+WzFRjv00dYS/fjZz1VTz03+AABtE+EGkqTs3h31lx+P8I3g3LT4c1VzF2MAQBtEuIHPiF4d9NxPRirRFaXV35bqhj+v0v6qOqvLAgDgpBBu4GdYj1S98NORSo6N1rpdZbrqT59q+z7ugwMAaDsINzjCkKwU/d+t56pbatNzqK5e8KlWf1tqdVkAAJwQwg1a1Cc9Qa/fNkpDslJUVtOgic98pudX7uBhmwCAsEe4wVF1SnRpydRzdNkZmWpwG933xkb99yv5XEkFAAhrhBscU6zToSd+dJbuvex0Oew2Lc3fq/FPfKJtxZVWlwYAQIsINzgum82mqeefppennqNOiS59U1SlcX/8WH/5lGkqAED4IdzghI3o1UH/uHO0zuubprpGj2a+uVETn1mlgtIaq0sDAMCHcIOTkp4Yo79MGaH7Lx+gmGi7Pv33fo2d/6Ge+Wi76hs9VpcHAADhBifPbrfpplG99O5d52tkrw6qqXfrt//YpEv+90Ot2FJsdXkAgHaOcINW69ExXi9PPUcPXTNYaQlObd9XrZsWf64fP/u5vi2ptro8AEA7ZTPtbEVoRUWFkpOTVV5erqSkJKvLiRgVtQ16LG+rFn+yQ40eo2iHTT8e1Uu3/0cfJcVEW10eAKCNO5m/34QbBNS/91Xpwbe+1oot+yRJybHRumVMb00+t4finFEWVwcAaKsIN8dAuAmN9zcX6Xdvb9a24qbnUqXGRevGc3po0rk9lZbgsrg6AEBbQ7g5BsJN6Lg9RkvX7dH/5m3VrubLxV1Rdl0zrJumnneaeqXFW1whAKCtINwcA+Em9Nweo2VfFeqpD/+t9bvLJUk2m3TxgAxNPe80DeuRKpvNZnGVAIBwRrg5BsKNdYwxWvVtqZ76cLve33zwkvHTOsXr2mHddPWZ3ZSZHGNhhQCAcEW4OQbCTXjYWlSpZz76Vm+u36sDDW5Jkt0mje7bSf85rJsuGpChmGiHxVUCAMIF4eYYCDfhpaquUW9v+E5/W7Nbq3eU+tqTYqJ0+ZAuuvqsbjozK0V2O9NWANCeEW6OgXATvnaUVOu1tbv1f2v3aE/ZAV97RpJLOadn6KIBGcru3VGuKEZ0AKC9IdwcA+Em/Hk8Riu379erXxRo+ddFqq53+/YluKI0pl8nXTwgQxf0S1dyLDcIBID2gHBzDISbtqWu0a1P/71fy78u0vKvi7Svss63z26TzuiWolG9O2pUnzQN65HKOh0AiFCEm2Mg3LRdHo/R+t1l+mdz0PHeINDLGWXX8B6pGtUnTaP6pOmMrslysFYHACIC4eYYCDeR47vyA/pk2359uq1En/y7REUVdX77450ODeyarCHdkjW4W4oGd0tW9w5x3FMHANogws0xEG4ikzFG/95XpU+27dcn20q0cvt+VdY2HtEvJS5aZ3RN1uDmwDOkWwr31gGANoBwcwyEm/bB7THaVlyl9bvL9OXucm3YXaZN31Wq3u05om96ossXdgZ3S9agrsk8/woAwgzh5hgIN+1XXaNb3xQ2BZ4Nu8u0YXe5vimqlKeF/wLSEpzqm56ofpmJ+n8ZieqTnqAeHeOUnuhiWgsALEC4OQbCDQ51oN6tjXvLtaF5dGfD7nJ9u79aR/uvIibaru4d4tS9Q7x6dIxTj45x6t4hTj06xqtrSqycUfbQfgEAaCcIN8dAuMHx1NQ3altxlbYUVmprcZU2F1bq25Iq7fn+QIujPF52m9QlJbY58MQ3h54438/EGO7JAwCtRbg5BsINWqvB7dGe7w9oZ2mNdu2v1s79Nc2va7SztFq1DUeu5zlUh3inL+hkJscoIzGm6WdSjDKSXEpPjGHkBwCO4mT+fkeFqCagzYt22NUzLV490+IldfLbZ4zRvso67Syt0c79zeHH+7q0RqXV9b4tv6DsqJ+RluBU+mGhJzOp6XVagksdE5zqEO/kZoUAcAyEGyAAbDab0pNilJ4Uo7N7djhif2Vtgy/oFJTWqLCiVkUVtSqqqFNhea2KK2vV4DYqqapXSVW9vv6u4pifl+CKUof4pqCT1hx4Oia41DHe2RyADr5OjSMMAWhfCDdACCTGRGtQ16bLzFvi8Rh9X1OvwopaFVfUqbCi1hd6CsubQtD+6jqVVterwW1UVdeoqrpG7SqtOaHPd0XZlRwb7dtS4qKVdMjvR9uSYqMJRgDaHMINEAbsdlvTyEuCSwO7HL2fMUYVtY0qra7X/qo67a+u1/6qepVW16mkqmnaa391nfZX1Wt/8zSY22NU1+hRcWWdiivrjv7mRxETfTAYJcZEK8EVpQRXlOJdDsW7opToilJ885YYE6V45yGvm/sluKIUG+3gMnoAIUG4AdoQm83mCxq90uKP29/jMaqsa1TFgQaVH2drqY8xUm2DR7UNdUc83uJk2W1SfHMwSmgOQ96QFOeMUky0Q3FOh2KjHYp1Hv46yvc6trlfnNOhGKdDcdEORTlYiA3gIMINEMHs9oNhKOskj20pGFXWNqiqzq3q5mmxqrrGpte1za/rD3ld5/a1GSN5jFRZ29jiYzFOldNhlyvaLleUQzHRdrmi7IqJdrT409cn2qGYqKafrij/3w//efj7OKPsinbY5HTYGY0CwhDhBkCLTiUYHcrjMTrQ4D56GKpzq7berZp6tw40uHWgvvGQ126/1wcamn+vb1RNg9t3s8V6t0f1bo8qFfjgdDzRDpuiHfbmwGOX0/f6OO2H7PP2cx52THSUXS6HXdFRB4+Jjjr82KZ9Ufamnw67TVEOm6LsdkU5bIq2N7VFO2wEMbQbhBsAQWW323xrcjIC+L7GNK0lqm0OPLUNbt/vLf2sO/x37+sGj2obj/3z0OMPfz5Zg9uowd1UQ7iz26Qoh13Rdltz4LH7fkY5mtsOCUNRjoOvHfam4w4NTt7+TW1N/aMO7XNEm012u00O28GfDvvBze77XYe8PtjvmMfYbLLbdcxj7LaDNSCyhUW4eeKJJ/Twww+rsLBQQ4YM0WOPPaYRI0Yctf+rr76q++67Tzt27FDfvn31+9//XpdddlkIKwZgNZvNpphoh2KiHUqJC93nuj1GDc0jRQ2N3p+mafSo0aMGd9NW793nNr72+kP2NTTvq/O+bjx0v/G9v/e4Q4+pP6y9sbmmRrdpqs/jafERIh6jprpCd7rCll8gag5bUYcFJvthQcoXyg455mhhq+mnFGW3N/eTf9Dyvl9zu9372tY0wma3NdVoO6Tdbmv6/33T+59g3+bveGjfpv2HvLared/BmmxHqa3pfXTI99SR72uXXFEOdUq07gHEloebV155Rbm5uVq4cKFGjhyp+fPna+zYsdqyZYvS09OP6P/pp5/q+uuv15w5c/TDH/5QL730ksaPH6+1a9dq0KBBFnwDAO1J0x8xR9hfIu9pDjmNbqNGj1Gj29McfJpeN7U1hSK3x6jxkL7etgZ3U7v3tdvTFK58xx/2Xn6/N7+f7ziPkdtt5DZGHk/TT7fHyNP807eZptqP2Oft73utFo49uP949953e4zcMlL4D7i1SWd1T9Frt42y7PMtf/zCyJEjdfbZZ+vxxx+XJHk8HmVlZennP/+5fvWrXx3Rf8KECaqurtZbb73lazvnnHM0dOhQLVy48Lifx+MXACDyGeMfipqCkY4Rqg4LXb6+Hrk98j/G2/fw4OUNXc1tjR5zZFBrPrbRY5oX2pvmrem1MfILaH77PS30bX7fw/saX03+fT2m6bsd0feQ9pbq8h5nmtua6jtkf3MN7ua+Q7NStOTm7ID+b9pmHr9QX1+vNWvWaPr06b42u92unJwcrVy5ssVjVq5cqdzcXL+2sWPHaunSpcEsFQDQhthszet8rC4ElrD0f/eSkhK53W5lZPgvM8zIyNDmzZtbPKawsLDF/oWFhS32r6urU13dwftzVFQc+7b2AACgbYv4O1/NmTNHycnJvi0r61QuagUAAOHO0nCTlpYmh8OhoqIiv/aioiJlZma2eExmZuZJ9Z8+fbrKy8t9W0FBQWCKBwAAYcnScON0OjVs2DDl5eX52jwej/Ly8pSd3fJCpOzsbL/+krR8+fKj9ne5XEpKSvLbAABA5LJ8rVVubq4mT56s4cOHa8SIEZo/f76qq6s1ZcoUSdKkSZPUtWtXzZkzR5I0bdo0jRkzRn/4wx80btw4LVmyRF988YWeeuopK78GAAAIE5aHmwkTJmjfvn2aMWOGCgsLNXToUC1btsy3aHjXrl2y2w8OMJ177rl66aWX9Jvf/Ea//vWv1bdvXy1dupR73AAAAElhcJ+bUOM+NwAAtD0n8/c74q+WAgAA7QvhBgAARBTCDQAAiCiEGwAAEFEINwAAIKIQbgAAQEQh3AAAgIhi+U38Qs17Wx+eDg4AQNvh/bt9Irfna3fhprKyUpJ4OjgAAG1QZWWlkpOTj9mn3d2h2OPxaO/evUpMTJTNZgvoe1dUVCgrK0sFBQXc/TiIOM+hwXkOHc51aHCeQyNY59kYo8rKSnXp0sXvsUwtaXcjN3a7Xd26dQvqZ/D08dDgPIcG5zl0ONehwXkOjWCc5+ON2HixoBgAAEQUwg0AAIgohJsAcrlcmjlzplwul9WlRDTOc2hwnkOHcx0anOfQCIfz3O4WFAMAgMjGyA0AAIgohBsAABBRCDcAACCiEG4AAEBEIdwEyBNPPKGePXsqJiZGI0eO1OrVq60uqU2ZM2eOzj77bCUmJio9PV3jx4/Xli1b/PrU1tbq9ttvV8eOHZWQkKBrrrlGRUVFfn127dqlcePGKS4uTunp6frFL36hxsbGUH6VNmXu3Lmy2Wy66667fG2c58DYs2ePbrjhBnXs2FGxsbE644wz9MUXX/j2G2M0Y8YMde7cWbGxscrJydHWrVv93qO0tFQTJ05UUlKSUlJS9JOf/ERVVVWh/iphze1267777lOvXr0UGxur3r1768EHH/R7/hDn+uR9+OGHuvzyy9WlSxfZbDYtXbrUb3+gzumGDRt03nnnKSYmRllZWXrooYcC8wUMTtmSJUuM0+k0ixYtMhs3bjRTp041KSkppqioyOrS2oyxY8eaxYsXm6+++srk5+ebyy67zHTv3t1UVVX5+txyyy0mKyvL5OXlmS+++MKcc8455txzz/Xtb2xsNIMGDTI5OTlm3bp15u233zZpaWlm+vTpVnylsLd69WrTs2dPM3jwYDNt2jRfO+f51JWWlpoePXqYm266yaxatcps377dvPvuu2bbtm2+PnPnzjXJyclm6dKlZv369eaKK64wvXr1MgcOHPD1ueSSS8yQIUPMZ599Zj766CPTp08fc/3111vxlcLW7NmzTceOHc1bb71lvv32W/Pqq6+ahIQE87//+7++Ppzrk/f222+be++917z22mtGknn99df99gfinJaXl5uMjAwzceJE89VXX5mXX37ZxMbGmieffPKU6yfcBMCIESPM7bff7vvd7XabLl26mDlz5lhYVdtWXFxsJJl//etfxhhjysrKTHR0tHn11Vd9fTZt2mQkmZUrVxpjmv5jtNvtprCw0NdnwYIFJikpydTV1YX2C4S5yspK07dvX7N8+XIzZswYX7jhPAfGL3/5SzN69Oij7vd4PCYzM9M8/PDDvraysjLjcrnMyy+/bIwx5uuvvzaSzOeff+7r88477xibzWb27NkTvOLbmHHjxpkf//jHfm1XX321mThxojGGcx0Ih4ebQJ3TP/3pTyY1NdXv341f/vKXpl+/fqdcM9NSp6i+vl5r1qxRTk6Or81utysnJ0crV660sLK2rby8XJLUoUMHSdKaNWvU0NDgd5779++v7t27+87zypUrdcYZZygjI8PXZ+zYsaqoqNDGjRtDWH34u/322zVu3Di/8ylxngPlzTff1PDhw/Wf//mfSk9P15lnnqmnn37at//bb79VYWGh33lOTk7WyJEj/c5zSkqKhg8f7uuTk5Mju92uVatWhe7LhLlzzz1XeXl5+uabbyRJ69ev18cff6xLL71UEuc6GAJ1TleuXKnzzz9fTqfT12fs2LHasmWLvv/++1Oqsd09ODPQSkpK5Ha7/f6hl6SMjAxt3rzZoqraNo/Ho7vuukujRo3SoEGDJEmFhYVyOp1KSUnx65uRkaHCwkJfn5b+d/DuQ5MlS5Zo7dq1+vzzz4/Yx3kOjO3bt2vBggXKzc3Vr3/9a33++ee688475XQ6NXnyZN95auk8Hnqe09PT/fZHRUWpQ4cOnOdD/OpXv1JFRYX69+8vh8Mht9ut2bNna+LEiZLEuQ6CQJ3TwsJC9erV64j38O5LTU1tdY2EG4Sd22+/XV999ZU+/vhjq0uJOAUFBZo2bZqWL1+umJgYq8uJWB6PR8OHD9fvfvc7SdKZZ56pr776SgsXLtTkyZMtri6y/PWvf9WLL76ol156SQMHDlR+fr7uuusudenShXPdjjEtdYrS0tLkcDiOuJqkqKhImZmZFlXVdt1xxx1666239MEHH6hbt26+9szMTNXX16usrMyv/6HnOTMzs8X/Hbz70DTtVFxcrLPOOktRUVGKiorSv/71L/3xj39UVFSUMjIyOM8B0LlzZw0YMMCv7fTTT9euXbskHTxPx/p3IzMzU8XFxX77GxsbVVpaynk+xC9+8Qv96le/0nXXXaczzjhDN954o/77v/9bc+bMkcS5DoZAndNg/ltCuDlFTqdTw4YNU15enq/N4/EoLy9P2dnZFlbWthhjdMcdd+j111/X+++/f8RQ5bBhwxQdHe13nrds2aJdu3b5znN2dra+/PJLv/+gli9frqSkpCP+0LRXF154ob788kvl5+f7tuHDh2vixIm+15znUzdq1KgjbmXwzTffqEePHpKkXr16KTMz0+88V1RUaNWqVX7nuaysTGvWrPH1ef/99+XxeDRy5MgQfIu2oaamRna7/58yh8Mhj8cjiXMdDIE6p9nZ2frwww/V0NDg67N8+XL169fvlKakJHEpeCAsWbLEuFwu8+yzz5qvv/7a3HzzzSYlJcXvahIc26233mqSk5PNihUrzHfffefbampqfH1uueUW0717d/P++++bL774wmRnZ5vs7Gzffu8lyhdffLHJz883y5YtM506deIS5eM49GopYzjPgbB69WoTFRVlZs+ebbZu3WpefPFFExcXZ1544QVfn7lz55qUlBTzxhtvmA0bNpgrr7yyxUtpzzzzTLNq1Srz8ccfm759+7bry5NbMnnyZNO1a1ffpeCvvfaaSUtLM//zP//j68O5PnmVlZVm3bp1Zt26dUaSmTdvnlm3bp3ZuXOnMSYw57SsrMxkZGSYG2+80Xz11VdmyZIlJi4ujkvBw8ljjz1munfvbpxOpxkxYoT57LPPrC6pTZHU4rZ48WJfnwMHDpjbbrvNpKammri4OHPVVVeZ7777zu99duzYYS699FITGxtr0tLSzN13320aGhpC/G3alsPDDec5MP7+97+bQYMGGZfLZfr372+eeuopv/0ej8fcd999JiMjw7hcLnPhhReaLVu2+PXZv3+/uf76601CQoJJSkoyU6ZMMZWVlaH8GmGvoqLCTJs2zXTv3t3ExMSY0047zdx7771+lxdzrk/eBx980OK/yZMnTzbGBO6crl+/3owePdq4XC7TtWtXM3fu3IDUbzPmkNs4AgAAtHGsuQEAABGFcAMAACIK4QYAAEQUwg0AAIgohBsAABBRCDcAACCiEG4AAEBEIdwAaPdsNpuWLl1qdRkAAoRwA8BSN910k2w22xHbJZdcYnVpANqoKKsLAIBLLrlEixcv9mtzuVwWVQOgrWPkBoDlXC6XMjMz/TbvU4FtNpsWLFigSy+9VLGxsTrttNP0t7/9ze/4L7/8Uv/xH/+h2NhYdezYUTfffLOqqqr8+ixatEgDBw6Uy+VS586ddccdd/jtLykp0VVXXaW4uDj17dtXb775ZnC/NICgIdwACHv33XefrrnmGq1fv14TJ07Uddddp02bNkmSqqurNXbsWKWmpurzzz/Xq6++qvfee88vvCxYsEC33367br75Zn355Zd688031adPH7/PeOCBB/Rf//Vf2rBhgy677DJNnDhRpaWlIf2eAAIkII/fBIBWmjx5snE4HCY+Pt5vmz17tjGm6Ynxt9xyi98xI0eONLfeeqsxxpinnnrKpKammqqqKt/+f/zjH8Zut5vCwkJjjDFdunQx995771FrkGR+85vf+H6vqqoyksw777wTsO8JIHRYcwPAcj/4wQ+0YMECv7YOHTr4XmdnZ/vty87OVn5+viRp06ZNGjJkiOLj4337R40aJY/Hoy1btshms2nv3r268MILj1nD4MGDfa/j4+OVlJSk4uLi1n4lABYi3ACwXHx8/BHTRIESGxt7Qv2io6P9frfZbPJ4PMEoCUCQseYGQNj77LPPjvj99NNPlySdfvrpWr9+vaqrq337P/nkE9ntdvXr10+JiYnq2bOn8vLyQlozAOswcgPAcnV1dSosLPRri4qKUlpamiTp1Vdf1fDhwzV69Gi9+OKLWr16tf785z9LkiZOnKiZM2dq8uTJuv/++7Vv3z79/Oc/14033qiMjAxJ0v33369bbrlF6enpuvTSS1VZWalPPvlEP//5z0P7RQGEBOEGgOWWLVumzp07+7X169dPmzdvltR0JdOSJUt02223qXPnznr55Zc1YMAASVJcXJzeffddTZs2TWeffbbi4uJ0zTXXaN68eb73mjx5smpra/Xoo4/qnnvuUVpamq699trQfUEAIWUzxhiriwCAo7HZbHr99dc1fvx4q0sB0Eaw5gYAAEQUwg0AAIgorLkBENaYOQdwshi5AQAAEYVwAwAAIgrhBgAARBTCDQAAiCiEGwAAEFEINwAAIKIQbgAAQEQh3AAAgIhCuAEAABHl/wPPPwqwncx9wQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final probabilities:\n",
            " tensor([[0.0000],\n",
            "        [0.0000],\n",
            "        [0.0000],\n",
            "        [0.0110],\n",
            "        [0.0000],\n",
            "        [0.0020],\n",
            "        [0.0270],\n",
            "        [0.0000],\n",
            "        [0.0080],\n",
            "        [0.0020],\n",
            "        [1.0000],\n",
            "        [1.0000],\n",
            "        [0.9980],\n",
            "        [0.9940],\n",
            "        [1.0000],\n",
            "        [0.9990],\n",
            "        [0.9970],\n",
            "        [0.9980],\n",
            "        [0.9910],\n",
            "        [1.0000]])\n",
            "\n",
            "Final predictions (>=0.5):\n",
            " tensor([[0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]])\n",
            "\n",
            "Targets:\n",
            " tensor([[0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]])\n",
            "\n",
            "Accuracy: 1.000\n",
            "TP=10, TN=10, FP=0, FN=0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Спостереження:**\n",
        "\n",
        "Loss зменшився і передбачення ідеально з таргетами. Модель має 100% точность.\n",
        "\n",
        "Метрики, які ми отримали:\n",
        "TP=10, TN=10, FP=0, FN=0."
      ],
      "metadata": {
        "id": "KXiIbmAMt8kD"
      }
    }
  ]
}