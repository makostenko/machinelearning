{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "В цьому домашньому завданні ми проведемо додаткові експерименти для рішення задачі бінарної класифікації і створимо ваш новий submission на змагання на Kaggle.\n",
        "\n",
        "-----------\n",
        "\n",
        "\n",
        "**Завдання 0**. Завантажте дані `train.csv`, `test.csv`, `sample_submission.csv` зі змагання на Kaggle - шукайте посилання в уроці [Запрошення до участі у Kaggle-змаганні.](https://data-loves.kwiga.com/courses/machine-learning-dlia-liudei/domashnie-zavdannia-zmagannia-z-kaggle)  Для завантаження потрібно долучитись до змагання (натиснути кнопку \"Join\").\n",
        "\n",
        "\n",
        "**Завдання 1**. **Збираємо весь код з попереднього ДЗ в одному місці.** В лекційному ноутбуці `Логістична регресія з ScikitLearn. Повна ML задача.ipynb` ми познайомились з поняттям пайплайнів, а також я показала, як компактно виглядає рішення МЛ задачі, якщо ми зберемо весь код разом.\n",
        "\n",
        "Оскільки ми далі будемо робити експерименти, які включають ті самі етапи попередньої обробки, але інше моделювання - буде зручно мати весь код компактно і під рукою. Тому зараз ми займемось збором коду до купи :) Після цього завдання для подальших експериментів ви можете перенести частини розвʼязку взагалі в окремий `.py` файл, аби було зручно імпортувати функції.\n",
        "\n",
        "Зі свого рішення в попередньому домашньому завданні (`Логістична регресія з scikit learn.ipynb`) зберіть усі кроки розвʼязку задачі разом з використанням `sklearn.Pipeline` за прикладом з лекції.\n",
        "\n",
        "Ваш код нижче має містити\n",
        "1. Читання даних з файлу (поза пайплайном).\n",
        "2. Розбиття на тренувальний і валідаційний набори, де валідаційний містить 20% даних (поза пайплайном).\n",
        "3. Виділення категоріальних і числових колонок (поза пайплайном).\n",
        "4. Підготовку категоріальних і числових колонок (частина пайплайну). В прикладі в лекції ми оформлювали обробку числових і категоріальних колонок в окремі трансформери `numeric_transformer`, `categorical_cols`. Рекоемндую зробити саме так, так потім зручніше вносити зміни :)\n",
        "5. Тренування лог регресії (частина пайплайну).\n",
        "6. Запуск пайплайну на тренування на трен. даних (поза пайплайном).\n",
        "7. Запуск пайплайну на передбачення на трен і вал. даних і вимір метрик якості ROC-AUC + вивдення Confusion Matrix (поза пайплайном).\n",
        "8. Збереження моделі в формат joblib (поза пайплайном).\n",
        "\n",
        "Ви це все вже зробили в попереднтьому ДЗ! Тож, тут просто заадча все зібрати разом.\n",
        "\n",
        "Нижче я додала підказки, що покроково ви маєте зробити. Якщо ви почуваєтесь впевнено, можете видалити ці підказки і реалізувати все самостійно, або ж - просто заповнити пропуски.\n",
        "\n",
        "Завдання оцінюється в 10 балів. Головний результат - аби код в фіналі був робочий. Бо за не робочий нам гроші ніхто не заплатить :)"
      ],
      "metadata": {
        "id": "gJ2A6t3mdEed"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from IPython.display import display"
      ],
      "metadata": {
        "id": "3Tz1hKn2dqtN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "raw_df = pd.read_csv(\"drive/MyDrive/1. ML/Модуль 2/Дані для задачі класифікації/train.csv\")"
      ],
      "metadata": {
        "id": "0LZialdo4IPZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c07c2e44-c3ee-48a6-f872-095edfb09ab0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv(\"drive/MyDrive/1. ML/Модуль 2/Дані для задачі класифікації/train.csv\")\n",
        "train_df, val_df = train_test_split(\n",
        "    train_df,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=train_df['Exited']\n",
        ")\n",
        "# Створюємо трен. і вал. набори\n",
        "target_col = 'Exited'\n",
        "input_cols = list(train_df.columns)[1:-1]\n",
        "train_inputs = train_df[input_cols]\n",
        "train_targets = train_df[target_col]\n",
        "\n",
        "val_inputs = val_df[input_cols]\n",
        "val_targets = val_df[target_col]\n",
        "\n",
        "# Виявляємо числові і категоріальні колонки\n",
        "numeric_cols = train_inputs.select_dtypes(include=np.number).columns.tolist()[:-1]\n",
        "categorical_cols = train_inputs.select_dtypes(include='object').columns.tolist()\n",
        "\n",
        "# Створюємо трансформери для числових і категоріальних колонок\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('scaler', ...)\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('onehot', ...)\n",
        "])\n",
        "\n",
        "# Комбінуємо трансформери для різних типів колонок в один препроцесор\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', ...),\n",
        "        ('cat', ...)\n",
        "    ])\n",
        "\n",
        "# Стоврюємо пайплайн, який спочатку запускає препроцесинг, потім тренуєм модель\n",
        "model_pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', ...),\n",
        "    ('classifier', ...)\n",
        "])\n",
        "\n",
        "# Тренуємо пайплайн\n",
        "....\n",
        "\n",
        "# Функція, щоб передбачати і рахувати метрики\n",
        "def predict_and_plot(model_pipeline, inputs, targets, name=''):\n",
        "    preds = model_pipeline.predict(inputs)\n",
        "    roc_auc = ...\n",
        "    print(f\"Area under ROC score on {name} dataset: {roc_auc:.2f}%\")\n",
        "    confusion_matrix_ = ...\n",
        "    plt.figure()\n",
        "    sns.heatmap(confusion_matrix_, annot=True, cmap='Blues')\n",
        "    plt.xlabel('Prediction')\n",
        "    plt.ylabel('Target')\n",
        "    plt.title('{} Confusion Matrix'.format(name))\n",
        "    plt.show()\n",
        "    return preds\n",
        "\n",
        "# Оцінюємо модель на трен і вал даних\n",
        "train_preds = predict_and_plot(...)\n",
        "val_preds = predict_and_plot(...)\n",
        "\n",
        "# Зберігаємо модель для подальшого використання\n",
        "joblib.dump(...)"
      ],
      "metadata": {
        "id": "MJSfIBEPdM8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Завдання 2**. Такс, у нас з вами є вже готовий пайплайн. Давайте проведемо нові експерименти.\n",
        "\n",
        "  Додайте в попередню обробку числових колонок генерацію polinomal features до степені 2 включно. Для цього створіть новий препроцесор і створіть новий пайплайн.\n",
        "\n",
        "  Запустіть пайплайн на тренування і виведіть метрики для тренувального і валідаційного набору. Напишіть, як вам модель? Чи спостерігається в цій моделі overfit чи underfit? Чи ця модель добре генералізує?"
      ],
      "metadata": {
        "id": "PXrc2NCa5lAK"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TjcmWMTOOjJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Завдання 3**. Тепер давайте створимо ще новий пайплайн, тільки тепер поліноміальні ознаки згенеруємо до степені 4. Зробіть висновок про якість моделі. Якщо вам подобається резульат якоїсь з моделей в цьому ДЗ - рекомендую зробити submission в змаганні."
      ],
      "metadata": {
        "id": "tkmEmHaP8Pen"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OsT-MDWuOkDY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Завдання 4. Перенавчання і регуляризація**.\n",
        "\n",
        "  Скачайте набір даних `regression_data.csv`. Звичайте набір даних з `regression_data.csv`, розбийте на train і test (в тест 20%) і натренуйте модель лінійної регресії з масштабуванням числових ознак і поліноміальними ознаками до степені **5 включно**.\n",
        "\n",
        "  Виміряйте якість прогностичної моделі і зробіть висновок, чи модель хороша, чи вона добре генералізує?\n"
      ],
      "metadata": {
        "id": "ozN2ONZGCBS6"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xbl0jQ3WOlgn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Завдання 5**. Натренуйте моделі Lasso(), Ridge(), ElasaticNet() на цих даних (з поліном ознаками до степені 20 включно), порівняйте якість з тою, яка була отримана з лінійною регресією. Яка модель найкраще генералізує і чому на ваш погляд (можливо треба буде для відповіді зробити додатковий аналіз ознак)?"
      ],
      "metadata": {
        "id": "JNUt-Q6UHkn7"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y93ItPYdOnpE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}